<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog - Luca Massaron</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <aside class="sidebar">
            <img src="photo.png" alt="Luca Massaron" class="profile-pic">
            <h1><a href="index.html">Luca Massaron</a></h1>
            <p class="subtitle">I build things. I talk about AI. I live in Italy.</p>
            <nav>
                <ul>
                    <li><a href="index.html">About</a></li>
                    <li><a href="books.html">Books</a></li>
                    <li class="active"><a href="blog.html">Blog</a></li>
                    <li><a href="kaggle.html">Kaggle</a></li>
                    <li><a href="talks.html">Talks</a></li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
            </nav>
        </aside>
        <main class="content">
            <h2>Blog</h2>
            <p>Here are some of my recent articles on Medium. You can find more on my <a href="https://medium.com/@lucamassaron" target="_blank">Medium profile</a>.</p>
            <ul>
                <li><a href="https://medium.com/p/1fbeb3b41846" target="_blank">Fine-tune Gemma-3–270M for Financial Sentiment Analysis</a></li>
                <li><a href="https://medium.com/p/66a613352f99" target="_blank">Fine-Tuning Gemma 3 1B for Function Calling: A Step-by-Step Guide</a></li>
                <li><a href="https://medium.com/p/d51489521707" target="_blank">Building agents with Gemini 2.5 Pro for the HF Agents Course</a></li>
                <li><a href="https://medium.com/p/805b5b8d87f2" target="_blank">Learning from Kaggle Competitions using Gemini 2.5: AI Mathematical Olympiad — Progress Prize 2</a></li>
                <li><a href="https://medium.com/p/1a025d2fc75d" target="_blank">Fine-Tuning Gemma 3 1B-IT for Financial Sentiment Analysis: A Step-by-Step Guide</a></li>
                <li><a href="https://medium.com/p/f80c219e2059" target="_blank">Training for Reasoning with GRPO — part II (a step by step explanation)</a></li>
                <li><a href="https://medium.com/p/5c94a6d57ec9" target="_blank">A Personal Assistant for knowledge management based on Gemini on Gemini 2.0 and Vertex AI</a></li>
                <li><a href="https://medium.com/p/881e1819f2df" target="_blank">Training for Reasoning with GRPO — part I ( project overview & results)</a></li>
                <li><a href="https://medium.com/p/0b149a6e48ae" target="_blank">Gemma 2 2B learns how to tutor in AI/ML</a></li>
                <li><a href="https://medium.com/p/25c5445f891e" target="_blank">Data Science AI Assistant with Gemma 2b-it: a RAG 101</a></li>
                <li><a href="https://medium.com/p/2907b06d2645" target="_blank">Sherlock Holmes Q&A Enhanced with Gemma 2b-it Fine-Tuning</a></li>
                <li><a href="https://medium.com/p/1ffcf0d0cd71" target="_blank">ML Olympiads: detect hallucinations in LLMs with Google Gemini</a></li>
                <li><a href="https://medium.com/p/ecda787a83ab" target="_blank">Higher performance with Gemma</a></li>
                <li><a href="https://medium.com/p/5c347e9d5a13" target="_blank">Fine-tuning a large language model on Kaggle Notebooks for solving real-world tasks — part 5: saving your work for reusing</a></li>
                <li><a href="https://medium.com/p/513629a55ac7" target="_blank">Fine-tuning a large language model on Kaggle Notebooks for solving real-world tasks — part 4 (LLama 2 strikes back)</a></li>
                <li><a href="https://medium.com/p/f15228f1c2a2" target="_blank">Fine-tuning a large language model on Kaggle Notebooks for solving real-world tasks — part 3</a></li>
                <li><a href="https://medium.com/p/f642e6149232" target="_blank">Fine-tuning a large language model on Kaggle Notebooks for solving real-world tasks — part 2</a></li>
                <li><a href="https://medium.com/me/stats/post/6233b0851998" target="_blank">Finetuning a large language model on Kaggle Notebooks for solving real-world tasks — part 1</a></li>
            </ul>
        </main>
    </div>
</body>
</html>
